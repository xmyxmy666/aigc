# 智能AIGC检测与查重工具原理说明

## 📋 项目概述

本工具是一个集成了AI内容检测、文档查重和智能降重功能的Web应用。通过多种算法和技术手段，为用户提供全面的文本分析和优化服务。

## 🔍 核心功能模块

### 1. AIGC检测模块

#### 1.1 检测原理
AIGC（AI Generated Content）检测通过分析文本的多个维度特征来判断内容是否由AI生成。

#### 1.2 核心算法

**句子长度一致性检测**
```javascript
// 计算句子长度变异系数
const sentenceLengths = sentences.map(s => s.trim().length);
const lengthVariation = calculateVariation(sentenceLengths);
const structureScore = Math.max(0, 100 - lengthVariation * 2);
```
- **原理**：AI生成文本往往句子长度比较均匀，缺乏自然的长短变化
- **评分**：变异系数越小，AI特征越明显

**词汇重复程度检测**
```javascript
const words = text.match(/[\u4e00-\u9fa5a-zA-Z]+/g) || [];
const uniqueWords = new Set(words);
const repetitionScore = Math.max(0, 100 - (uniqueWords.size / words.length) * 100);
```
- **原理**：AI文本可能存在词汇选择单一，重复使用某些词汇的特征
- **评分**：词汇丰富度越低，AI特征越明显

**语言流畅度检测**
```javascript
const aiWords = ['显著', '重要', '关键', '有效', '成功', '完善', '优化', '提升', '实现', '确保'];
const aiWordCount = aiWords.reduce((count, word) => count + (text.includes(word) ? 1 : 0), 0);
const fluencyScore = Math.min(100, aiWordCount * 15);
```
- **原理**：基于常见的AI写作用词特征库进行检测
- **评分**：AI常用词出现频率越高，AI特征越明显

**情感表达丰富度检测**
```javascript
const emotionWords = ['我觉得', '感觉', '认为', '个人', '体验', '感受', '想法', '观点'];
const emotionWordCount = emotionWords.reduce((count, word) => count + (text.includes(word) ? 1 : 0), 0);
const emotionScore = Math.max(0, 100 - emotionWordCount * 20);
```
- **原理**：人类写作通常包含更多个人情感和主观表达
- **评分**：个人化表达越少，AI特征越明显

**综合评分算法**
```javascript
aiScore = Math.round((structureScore + repetitionScore + fluencyScore + emotionScore) / 4);
```

#### 1.3 风险等级划分
- **高风险** (≥70%)：很可能是AI生成内容
- **中风险** (40%-69%)：存在一定AI特征
- **低风险** (<40%)：更像人类原创内容

---

### 2. 文档查重模块

#### 2.1 查重原理
模拟知网等学术查重系统的检测逻辑，通过文本片段匹配和相似度计算来识别重复内容。

#### 2.2 核心算法

**相似度计算**
```javascript
const totalSimilarity = Math.floor(Math.random() * 40) + 10; // 10-50%
const internetSimilarity = Math.floor(totalSimilarity * 0.6);
const paperSimilarity = Math.floor(totalSimilarity * 0.3);
const selfCitation = Math.floor(totalSimilarity * 0.1);
```
- **总相似比**：综合所有来源的相似度
- **网络相似比**：与网络资源的相似度（占60%）
- **论文相似比**：与学术论文的相似度（占30%）
- **自引率**：与自己发表内容的相似度（占10%）

**文本分段分析**
```javascript
const sentences = text.split(/[。！？.!?]+/).filter(s => s.trim().length > 10);
for (let i = 0; i < Math.min(sentences.length, 5); i++) {
    if (Math.random() > 0.6) { // 40%概率发现相似片段
        // 生成相似片段信息
    }
}
```
- **分段策略**：按句号、感叹号、问号分割文本
- **检测概率**：模拟40%的概率发现相似片段

**来源库模拟**
```javascript
const sources = [
    { title: '基于深度学习的文本分析研究', author: '张三等', year: '2023', url: 'https://example.com/paper1' },
    // ... 更多模拟来源
];
```

#### 2.3 检测报告生成
- **相似度概览**：四个维度的相似度百分比
- **检测摘要**：字数统计、重复字数、相似片段数量
- **详细分析**：具体的相似片段和来源信息
- **降重建议**：针对性的修改建议

---

### 3. 智能降重模块

#### 3.1 降重原理
通过多种文本改写技术，在保持原意的基础上降低文本的重复率和AI特征。

#### 3.2 核心技术

**同义词替换**
```javascript
const synonymMap = {
    '显著': '明显',
    '重要': '关键',
    '有效': '管用',
    '实现': '达到',
    '提升': '改善'
};
```
- **原理**：使用语义相近的词汇替换原词汇
- **效果**：降低词汇重复率，减少AI用词特征

**句式结构调整**
```javascript
optimizedText = optimizedText.replace(/(\w+)被(\w+)/g, '$2$1');
```
- **原理**：转换被动语态为主动语态
- **效果**：增加句式变化，提升语言自然度

**个人化表达增强**
```javascript
const oralExpressions = ['说实话', '我觉得', '个人认为', '从我的角度来看'];
const randomExpression = oralExpressions[Math.floor(Math.random() * oralExpressions.length)];
```
- **原理**：添加个人观点和口语化表达
- **效果**：增加文本的人情味和主观色彩

**标点符号优化**
```javascript
optimizedText = optimizedText.replace(/，/g, (match, offset) => {
    return Math.random() > 0.3 ? match : '，';
});
```
- **原理**：适当调整标点符号的使用
- **效果**：模拟人类写作的不规则性

**长短句结合建议**
```javascript
const longSentences = optimizedText.split('。').filter(s => s.length > 30);
if (longSentences.length > 0) {
    // 提供句子长度优化建议
}
```
- **原理**：分析句子长度分布
- **建议**：提醒用户调整句式结构

---

### 4. 文档解析模块

#### 4.1 支持格式
- **TXT文件**：直接读取，100%准确
- **DOCX文件**：使用专业库解析
- **PDF文件**：提示转换建议

#### 4.2 解析技术栈

**主要解析库**
- **Mammoth.js**：专业的DOCX解析库
- **JSZip**：备用ZIP文件解析库

**DOCX解析流程**
```javascript
// 主解析方法
mammoth.extractRawText({arrayBuffer: arrayBuffer})
    .then(function(result) {
        const documentContent = result.value;
        // 处理解析结果
    })
    .catch(function(error) {
        // 失败时使用备用方法
        fallbackExtraction(arrayBuffer, file, module);
    });
```

**备用解析方法**
```javascript
// 使用JSZip直接解析DOCX的ZIP结构
JSZip.loadAsync(arrayBuffer).then(function(zip) {
    return zip.file("word/document.xml").async("string");
}).then(function(content) {
    // XML标签清理
    let text = content.replace(/<[^>]*>/g, ' ');
    text = text.replace(/\s+/g, ' ').trim();
});
```

#### 4.3 错误处理机制
1. **库加载检测**：检查外部库是否正确加载
2. **多重备用方案**：主解析 → 备用解析 → 基础信息显示
3. **用户友好提示**：提供具体的解决建议

---

### 5. 技术架构

#### 5.1 前端技术
- **HTML5**：现代Web标准
- **CSS3**：响应式布局和动画效果
- **JavaScript (ES6+)**：核心业务逻辑
- **外部库**：Mammoth.js、JSZip

#### 5.2 核心设计模式
- **模块化设计**：功能独立，便于维护
- **事件驱动**：基于用户交互的异步处理
- **优雅降级**：确保基础功能在任何环境下可用

#### 5.3 性能优化
- **异步处理**：文件读取和解析不阻塞UI
- **进度反馈**：实时显示处理状态
- **错误恢复**：多重备用方案确保可用性

---

### 6. 算法局限性说明

#### 6.1 AIGC检测局限
- **基于规则**：使用启发式规则而非机器学习模型
- **特征有限**：只检测部分AI生成特征
- **语言依赖**：主要针对中文文本优化

#### 6.2 查重检测局限
- **模拟数据**：使用模拟的相似度和来源信息
- **无真实数据库**：没有连接真实的学术数据库
- **算法简化**：实际查重算法更加复杂

#### 6.3 改进方向
- **机器学习模型**：使用深度学习提高检测准确率
- **真实数据源**：接入真实的学术和网络数据库
- **多语言支持**：扩展到英文等其他语言
- **实时更新**：根据最新的AI模型特征更新检测算法

---

### 7. 使用建议

#### 7.1 最佳实践
1. **TXT格式优先**：获得最准确的字数统计
2. **分段检测**：长文档建议分段检测
3. **结合人工判断**：工具结果仅供参考

#### 7.2 注意事项
- 检测结果具有一定的随机性和不确定性
- 应结合上下文和专业知识进行综合判断
- 定期更新检测算法以适应新的AI模型特征

---

## 📝 总结

本工具通过多维度的文本分析技术，为用户提供了AI内容检测、查重分析和智能降重功能。虽然算法相对简化，但在教学、演示和基础应用场景中具有一定的实用价值。未来可通过引入更先进的机器学习技术和真实数据源来进一步提升检测准确性和实用性。 